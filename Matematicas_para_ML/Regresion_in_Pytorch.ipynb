{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión en PyTorch"
      ],
      "metadata": {
        "id": "oJr7NMm7fEun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este cuaderno, usamos la librería PyTorch **diferenciación automática** para ajustar una recta a puntos de datos. Así, aquí usamos el cálculo para resolver el mismo problema de regresión que usamos para resolver la Pseudoinversa de Moore-Penrose en el [*Cuaderno de Álgebra Lineal II*](https://github.com/joanby/matematicas-ml/blob/master/notebooks/2-linear-algebra-ii.ipynb)."
      ],
      "metadata": {
        "id": "baplWgStfGb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ooPJr4DIfMY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([0,1,2,3,4,5,6,7.])\n",
        "x"
      ],
      "metadata": {
        "id": "328M6IKrfXjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores $y$ se crearon utilizando la ecuación de una recta $y = mx + b$. De este modo, sabemos cuáles son los parámetros del modelo que hay que aprender, digamos, $m = -0,5$ y $b = 2$. Se ha añadido ruido aleatorio distribuido normalmente para simular el error de muestreo:"
      ],
      "metadata": {
        "id": "hRRTanMSgYf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y=-0.5*x+2 + torch.normal(mean=torch.zeros(8),std=0.2)"
      ],
      "metadata": {
        "id": "7QaFAj7_gfpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la reproducibilidad de esta demostración, he aquí un ejemplo fijo de los valores $y$ obtenidos ejecutando la línea comentada anteriormente:"
      ],
      "metadata": {
        "id": "dTzsppSKgzqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.tensor([1.86,1.31,.62,.33,.09,-.67,-1.23,-1.37]) #puntuacion de olvido delpaciente"
      ],
      "metadata": {
        "id": "nhgbLJT5g4sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "00eCtz7khkXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots()\n",
        "plt.title('Ensayo Clinico')\n",
        "plt.xlabel('Dosis de Droga')\n",
        "plt.ylabel('Nivel de Olvido')\n",
        "ax.scatter(x,y)"
      ],
      "metadata": {
        "id": "xMBvNaeUhnSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializar el parámetro de pendiente $m$ con un valor «aleatorio» de 0,9..."
      ],
      "metadata": {
        "id": "H7zIYNLElFyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N.B.**: En esta sencilla demostración, podríamos empezar adivinando valores de parámetros aproximadamente correctos. O podríamos utilizar un método algebraico (por ejemplo, la pseudoinversa de Moore-Penrose) o estadístico (por ejemplo, la regresión por mínimos cuadrados ordinarios) para resolver los parámetros rápidamente. Sin embargo, esta pequeña demostración de aprendizaje automático con dos parámetros y ocho puntos de datos puede ampliarse a millones de parámetros y millones de puntos de datos. Los demás enfoques -adivinanzas, álgebra, estadística- no se acercan a este escalado)."
      ],
      "metadata": {
        "id": "CLLTr5nplHZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=torch.tensor([0.9]).requires_grad_()\n",
        "m"
      ],
      "metadata": {
        "id": "pXC3pR7Pldpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...y hacer lo mismo para el parámetro $y$-intercepto $b$:"
      ],
      "metadata": {
        "id": "dIJnCdVcmHUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b=torch.tensor([0.1]).requires_grad_()\n",
        "b"
      ],
      "metadata": {
        "id": "u8RwZy4hmEPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression(my_x,my_m,my_b):\n",
        "  return my_m*my_x+my_b"
      ],
      "metadata": {
        "id": "gy0n-9JOmXZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_plot(my_x,my_y,my_m,my_b):\n",
        "  fig,ax=plt.subplots()\n",
        "  plt.scatter(my_x,my_y)\n",
        "  x_min,x_max=ax.get_xlim()\n",
        "  y_min=regression(x_min,my_m,my_b).detach().item()\n",
        "  y_max=regression(x_max,my_m,my_b).detach().item()\n",
        "\n",
        "  ax.set_xlim([x_min,x_max])\n",
        "  plt.plot([x_min,x_max],[y_min,y_max])\n"
      ],
      "metadata": {
        "id": "0_ZmjgNJmtGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_plot(x,y,m,b)"
      ],
      "metadata": {
        "id": "I7lxWxiaomq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}