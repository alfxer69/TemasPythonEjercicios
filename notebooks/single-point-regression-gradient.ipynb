{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfxer69/TemasPythonEjercicios/blob/main/notebooks/single-point-regression-gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQvcmWWNd4Y"
      },
      "source": [
        "# Gradiente de una regresión de un solo punto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JtUZ9KYNd4Z"
      },
      "source": [
        "En este cuaderno, calculamos el gradiente del coste cuadrático con respecto a los parámetros de un modelo de regresión en línea recta. Mantenemos las derivadas parciales lo más simples posible limitando el modelo al manejo de un único punto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdScrjQCNd4Z"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnFhWE9kNd4d"
      },
      "source": [
        "Usemos los mismos datos que usamos en el cuaderno [*Regresión en PyTorch*](https://github.com/joanby/matematicas-ml/blob/master/notebooks/regression-in-pytorch.ipynb) así como para demostrar la Pseudoinversa de Moore-Penrose en el cuaderno [*Álgebra Lineal II*](https://github.com/joanby/matematicas-ml/blob/master/notebooks/2-linear-algebra-ii.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oem10L3iNd4d"
      },
      "source": [
        "xs = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPZsXuwWNd4f"
      },
      "source": [
        "ys = torch.tensor([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM6hk9NeNd4i"
      },
      "source": [
        "La pendiente de la recta viene dada por $y = mx + b$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtyilFoYNd4i"
      },
      "source": [
        "def regression(my_x, my_m, my_b):\n",
        "    return my_m*my_x + my_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROV3p3BHNd4l"
      },
      "source": [
        "Inicialicemos $m$ y $b$ con los mismos valores «aleatorios» cercanos a cero que hicimos en el cuaderno *Regresión en PyTorch*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmiBbvH1Nd4l"
      },
      "source": [
        "m = torch.tensor([0.9]).requires_grad_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRxe0rU9Nd4n"
      },
      "source": [
        "b = torch.tensor([0.1]).requires_grad_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iu4uKsqNd4r"
      },
      "source": [
        "Para mantener las derivadas parciales lo más simple posible, vamos a avanzar con una sola instancia $i$ de los ocho posibles puntos de datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ttss5lTNd4s"
      },
      "source": [
        "i = 7\n",
        "x = xs[i]\n",
        "y = ys[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO7ozmjeNd4u",
        "outputId": "fc2db7ca-f41e-496a-f7b5-836b2a9404a4"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63IzdS1Nd4x",
        "outputId": "7d75ef4f-fe5d-4f7c-9d56-bb0d014cc348"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.3700)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVkbo0oPNd4z"
      },
      "source": [
        "**Paso 1**: Paso hacia adelante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_bUxX__Nd4z"
      },
      "source": [
        "Podemos fluir el tensor escalar $x$ a través de nuestro modelo de regresión para producir $\\hat{y}$, una estimación de $y$. Antes de cualquier modelo de formación, se trata de una estimación arbitraria:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBB2iwPiNd40",
        "outputId": "2fccb742-b4f7-4950-e0b8-d8e3cf8e3da4"
      },
      "source": [
        "yhat = regression(x, m, b)\n",
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.4000], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hy2sDlNNd42"
      },
      "source": [
        "**Paso 2**: Comparar $\\hat{y}$ con el valor real de $y$ para calcular el coste $C$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtHOeylJNd43"
      },
      "source": [
        "En el cuaderno *Regresión en PyTorch*, usamos el error cuadrático medio, que promedia el coste cuadrático sobre múltiples puntos de datos. Con un único punto de datos, aquí podemos usar sólo el coste cuadrático. Se define por: $$ C = (\\hat{y} - y)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-THZMH0Nd43"
      },
      "source": [
        "def squared_error(my_yhat, my_y):\n",
        "    return (my_yhat - my_y)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LSKXx5XNd45",
        "outputId": "e9b24796-e3c5-4a35-8a82-994f6d16ded5"
      },
      "source": [
        "C = squared_error(yhat, y)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([60.3729], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu4nlO3-Nd47"
      },
      "source": [
        "**Paso 3**: Utilizar autodiff para calcular el gradiente de $C$ en función de los parámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk9Lx-gTNd48"
      },
      "source": [
        "C.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXQJxYduNd4-"
      },
      "source": [
        "La derivada parcial de $C$ Con respecto a $m$ ($\\frac{\\partial C}{\\partial m}$) es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yQ7w1bfNd4-",
        "outputId": "640a84b0-b08c-439e-c7d9-8c0291abf361"
      },
      "source": [
        "m.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([108.7800])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGK1NwomNd5B"
      },
      "source": [
        "Y la derivada parcial de $C$ con respecto a $b$ ($\\frac{\\partial C}{\\partial b}$) es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIeBu-tINd5B",
        "outputId": "79a1a6b7-a068-4783-8b3d-24e5569266f2"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15.5400])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK1tyH4WNd5E"
      },
      "source": [
        "Volver a las diapositivas de *Cálculo II*  aquí para derivar $\\frac{\\partial C}{\\partial m}$ y $\\frac{\\partial C}{\\partial b}$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTgfR-wINd5F"
      },
      "source": [
        "$$ \\frac{\\partial C}{\\partial m} = 2x(\\hat{y} - y) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKjWDa4QNd5F",
        "outputId": "5d29bb67-6538-4ff9-a868-85927f114c21"
      },
      "source": [
        "2*x*(yhat.item()-y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(108.7800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCV3zMIjNd5H"
      },
      "source": [
        "$$ \\frac{\\partial C}{\\partial b} = 2(\\hat{y}-y) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNrOSpcONd5H",
        "outputId": "73b37a87-7535-4049-9587-aa8b1831c69f"
      },
      "source": [
        "2*(yhat.item()-y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.5400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXor7Ev7Nd5J"
      },
      "source": [
        "### El gradiente del Coste, $\\nabla C$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeII8EHQNd5K"
      },
      "source": [
        "El gradiente del coste, que se simboliza $\\nabla C$ (pronunciado «nabla C»), es un vector de todas las derivadas parciales de $C$ con respecto a cada uno de los parámetros individuales del modelo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVnD7j3HNd5K"
      },
      "source": [
        "$\\nabla C = \\nabla_p C = \\left[ \\frac{\\partial{C}}{\\partial{p_1}}, \\frac{\\partial{C}}{\\partial{p_2}}, \\cdots, \\frac{\\partial{C}}{\\partial{p_n}} \\right]^T $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILK7BRLJNd5K"
      },
      "source": [
        "En este caso, sólo hay dos parámetros, $b$ y $m$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yq3BQ3YNd5L"
      },
      "source": [
        "$\\nabla C = \\left[ \\frac{\\partial{C}}{\\partial{b}}, \\frac{\\partial{C}}{\\partial{m}} \\right]^T $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsZhOKFZNd5L",
        "outputId": "d3dc7def-3e43-40c2-9eb2-d7b86db95994"
      },
      "source": [
        "gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T\n",
        "gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 15.5400],\n",
              "        [108.7800]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}